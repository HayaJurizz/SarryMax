from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List
import pandas as pd
import numpy as np
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tools.sm_exceptions import ConvergenceWarning
import warnings
import os
from .MapModels import BarangayCoordItem, BarangayCoordsResponse
from math import isnan

# =========================================================
# FastAPI app
# =========================================================
app = FastAPI(
    title="SARIMA Crime Forecast API",
    description="Forecast monthly crimes + show top crimes and high-risk barangays using SARIMA(0,1,1)(0,1,1)[12].",
    version="1.2.0",
)

# =========================================================
# Pydantic models (for clean JSON responses)
# =========================================================
class ForecastItem(BaseModel):
    date: str
    forecast: float
    lower_ci: float
    upper_ci: float

class ForecastResponse(BaseModel):
    status: str
    horizon: int
    data: List[ForecastItem]


class TopCrimeItem(BaseModel):
    crime_type: str
    total: int

class TopCrimesResponse(BaseModel):
    status: str
    top_n: int
    data: List[TopCrimeItem]


class TopBarangayItem(BaseModel):
    barangay: str
    total: int

class TopBarangaysResponse(BaseModel):
    status: str
    top_n: int
    data: List[TopBarangayItem]


class PossibleCrimeItem(BaseModel):
    crime_type: str
    total_5years: int

class PossibleCrimesResponse(BaseModel):
    status: str
    month: int
    month_name: str
    data: List[PossibleCrimeItem]


# =========================================================
# Globals (shared data/model)
# =========================================================
ts = None                   # monthly total crimes (city-wide)
sarima_model = None         # SARIMA(0,1,1)(0,1,1,12) model
df_global = None            # cleaned full dataframe
top_crimes_overall = None   # Series: crime_type -> total
top_barangays_overall = None# Series: barangay -> total
top_crimes_by_month = None  # DataFrame: month, crime_type, total
barangay_coords_global = None  # DataFrame: barangay, lat, lng, total


# =========================================================
# Helper
# =========================================================
def month_name_from_int(m: int) -> str:
    names = {
        1: "January", 2: "February", 3: "March", 4: "April",
        5: "May", 6: "June", 7: "July", 8: "August",
        9: "September", 10: "October", 11: "November", 12: "December"
    }
    return names.get(m, "Unknown")


def load_and_train():
    """
    1. Load davao_crime_5years.csv
    2. Clean data
    3. Create monthly time series
    4. Train SARIMA(0,1,1)(0,1,1)[12]
    5. Pre-compute:
       - top crimes overall
       - top barangays overall
       - top 3 crimes per calendar month
    """
    global ts, sarima_model, df_global
    global top_crimes_overall, top_barangays_overall, top_crimes_by_month

    # 1) Path to CSV  --------------------------------------
    base_dir = os.path.dirname(os.path.abspath(__file__))
    data_dir = os.path.abspath(os.path.join(base_dir, "..", "data"))

    # Try known candidate filenames first (accounts for spaces/parentheses)
    candidates = [
        "clean_davao_crime_5years.csv",
        "clean_davao_crime_5years (1).csv",
        "clean_davao_crime_5years(1).csv",
        "davao_crime_5years.csv",
    ]

    csv_path = None
    for name in candidates:
        p = os.path.join(data_dir, name)
        if os.path.exists(p):
            csv_path = p
            break

    # Fallback: scan data_dir for any CSV that looks like the dataset
    if csv_path is None and os.path.exists(data_dir):
        for fname in os.listdir(data_dir):
            if not fname.lower().endswith(".csv"):
                continue
            ln = fname.lower()
            if ("davao" in ln and "crime" in ln) or ("clean_davao" in ln):
                csv_path = os.path.join(data_dir, fname)
                break

    if csv_path is None:
        found = os.listdir(data_dir) if os.path.exists(data_dir) else []
        raise FileNotFoundError(
            f"Could not find a matching CSV in {data_dir}. Tried candidates {candidates}. Found: {found}"
        )

    df = pd.read_csv(csv_path)

    # Expect columns:
    # id, date, barangay, crime_type, crime_count, latitude, longitude

    # 2) CLEANING  -----------------------------------------
    df["date"] = pd.to_datetime(df["date"], errors="coerce")
    df = df.dropna(subset=["date"]).sort_values("date")

    # keep only positive crimes
    df["crime_count"] = pd.to_numeric(df["crime_count"], errors="coerce")
    df = df[df["crime_count"] > 0]

    # strip text fields
    df["barangay"] = df["barangay"].astype(str).str.strip()
    df["crime_type"] = df["crime_type"].astype(str).str.strip()

    df = df.drop_duplicates()

    df_global = df.copy()

    # 3) MONTHLY TOTAL CRIMES (CITY-WIDE)  -----------------
    # group by month start, sum crime_count
    monthly = (
        df.set_index("date")
          .groupby(pd.Grouper(freq="MS"))["crime_count"]
          .sum()
          .asfreq("MS", fill_value=0)
    )

    ts = monthly.astype(float)

    # 4) TRAIN SARIMA(0,1,1)(0,1,1)[12]  -------------------

    model = SARIMAX(
        ts,
        order=(0, 1, 1),
        seasonal_order=(0, 1, 1, 12),
        enforce_stationarity=True,
        enforce_invertibility=False,  # allow non-invertible start
    )

    # Robust fitting: try several optimizers and increase max iterations.
    def fit_with_retries(sarimax_model):
        methods = ["lbfgs", "powell", "bfgs", "nm"]
        for method in methods:
            try:
                with warnings.catch_warnings(record=True) as w:
                    warnings.simplefilter("always")
                    res = sarimax_model.fit(disp=False, method=method, maxiter=300)
                    # If a ConvergenceWarning was raised, try next method
                    conv_warn = any(issubclass(x.category, ConvergenceWarning) for x in w)
                    if not conv_warn:
                        print(f"‚úÖ Fitted with method={method}")
                        return res
                    else:
                        print(f"‚ö†Ô∏è ConvergenceWarning with method={method}; trying next")
            except Exception as e:
                print(f"‚ùå fit failed with method={method}: {e}")

        # Final fallback: attempt a longer-run lbfgs fit and accept its result
        try:
            print("üîÅ Final fallback: trying lbfgs with maxiter=1000")
            return sarimax_model.fit(disp=False, method="lbfgs", maxiter=1000)
        except Exception as e:
            print("‚ùå Final fallback fit failed:", e)
            # re-raise so startup prints the error and stops
            raise

    sarima_model_local = fit_with_retries(model)

    # assign after training
    global sarima_model
    sarima_model = sarima_model_local

    # 5) PRE-COMPUTE INSIGHTS  -----------------------------

    # 5a) Overall top crimes
    top_crimes_overall = (
        df.groupby("crime_type")["crime_count"]
          .sum()
          .sort_values(ascending=False)
    )

    # 5b) Overall top barangays
    top_barangays_overall = (
        df.groupby("barangay")["crime_count"]
          .sum()
          .sort_values(ascending=False)
    )

    # 5c) Top 3 crimes per calendar month (1‚Äì12)
    df["month"] = df["date"].dt.month
    monthly_crime_type = (
        df.groupby(["month", "crime_type"])["crime_count"]
          .sum()
          .reset_index()
          .rename(columns={"crime_count": "total"})
    )

    top_crimes_by_month = (
        monthly_crime_type
        .sort_values(["month", "total"], ascending=[True, False])
        .groupby("month")
        .head(3)
        .reset_index(drop=True)
    )

    # 5d) Barangay centroids + totals for mapping
    try:
        barangay_coords = (
            df.groupby("barangay")[ ["latitude", "longitude", "crime_count"] ]
              .agg({"latitude": "mean", "longitude": "mean", "crime_count": "sum"})
              .reset_index()
              .rename(columns={"latitude": "lat", "longitude": "lng", "crime_count": "total"})
        )
        barangay_coords_global = barangay_coords
    except Exception:
        barangay_coords_global = None

    print("‚úÖ Model trained on", len(ts), "months.")
    print("   Best model (fixed): SARIMA(0,1,1)(0,1,1)[12]")


def _fit_sarima_with_retries(series, order=(0,1,1), seasonal_order=(0,1,1,12)):
    """Fit SARIMAX with multiple optimizers/retries; return results."""
    model = SARIMAX(series, order=order, seasonal_order=seasonal_order,
                    enforce_stationarity=True, enforce_invertibility=False)

    methods = ["lbfgs", "powell", "bfgs", "nm"]
    for method in methods:
        try:
            with warnings.catch_warnings(record=True) as w:
                warnings.simplefilter("always")
                res = model.fit(disp=False, method=method, maxiter=300)
                conv_warn = any(issubclass(x.category, ConvergenceWarning) for x in w)
                if not conv_warn:
                    return res
        except Exception:
            continue

    # final fallback
    return model.fit(disp=False, method="lbfgs", maxiter=1000)


def compute_holdout_metrics(horizon: int = 12):
    """Compute RMSE and MAPE using last `horizon` months as holdout.
    Returns dict {rmse, mape, horizon}.
    """
    if ts is None:
        raise RuntimeError("Time series not available; ensure model/data loaded.")

    if horizon <= 0 or horizon >= len(ts):
        raise ValueError("horizon must be >0 and less than length of series")

    train = ts.iloc[:-horizon]
    test = ts.iloc[-horizon:]

    # fit on train
    res = _fit_sarima_with_retries(train)

    # forecast
    fc = res.get_forecast(steps=horizon)
    mean = fc.predicted_mean

    # align
    pred = np.asarray(mean)
    actual = np.asarray(test)

    rmse = float(np.sqrt(np.mean((actual - pred) ** 2)))

    nonzero = actual != 0
    if nonzero.sum() == 0:
        mape = float('nan')
    else:
        mape = float(np.mean(np.abs((actual[nonzero] - pred[nonzero]) / actual[nonzero])) * 100)

    return {"rmse": rmse, "mape": mape, "horizon": horizon}


# =========================================================
# Run training once when the API starts
# =========================================================
@app.on_event("startup")
def startup_event():
    try:
        load_and_train()
    except Exception as e:
        print("‚ùå Error during startup training:", e)


# =========================================================
# ROUTES
# =========================================================
@app.get("/", tags=["health"])
def health_check():
    return {
        "status": "ok",
        "message": "SARIMA API is running.",
        "model_ready": bool(sarima_model is not None and ts is not None),
    }


# ---------- 1) FORECAST TOTAL CRIMES (MONTHLY) ----------
@app.get("/forecast", response_model=ForecastResponse, tags=["forecast"])
def get_forecast(horizon: int = 12):
    """
    Get next N months crime forecast (city-wide total).
    Default horizon = 12 months.
    """
    global ts, sarima_model

    if ts is None or sarima_model is None:
        raise HTTPException(status_code=500, detail="Model not trained.")

    if horizon <= 0 or horizon > 60:
        raise HTTPException(status_code=400, detail="horizon must be between 1 and 60 months.")

    forecast_res = sarima_model.get_forecast(steps=horizon)
    mean = forecast_res.predicted_mean
    ci = forecast_res.conf_int()

    # future dates starting from next month
    future_dates = pd.date_range(
        start=ts.index[-1] + pd.DateOffset(months=1),
        periods=horizon,
        freq="MS",
    )

    items: List[ForecastItem] = []
    for i in range(horizon):
        items.append(
            ForecastItem(
                date=str(future_dates[i].date()),
                forecast=float(mean.iloc[i]),
                lower_ci=float(ci.iloc[i, 0]),
                upper_ci=float(ci.iloc[i, 1]),
            )
        )

    return ForecastResponse(status="success", horizon=horizon, data=items)


# ---------- 2) TOP CRIMES OVERALL -----------------------
@app.get("/top-crimes", response_model=TopCrimesResponse, tags=["insights"])
def get_top_crimes(top_n: int = 10):
    """
    Return top N crime types based on 5-year historical data.
    Example: /top-crimes?top_n=5
    """
    global top_crimes_overall

    if top_crimes_overall is None:
        raise HTTPException(status_code=500, detail="Top crimes not available (model not initialized).")

    if top_n <= 0:
        raise HTTPException(status_code=400, detail="top_n must be positive.")

    series = top_crimes_overall.head(top_n)

    data = [
        TopCrimeItem(crime_type=str(idx), total=int(val))
        for idx, val in series.items()
    ]

    return TopCrimesResponse(status="success", top_n=len(data), data=data)


# ---------- 3) TOP BARANGAYS (PINAKAMADAMING KRIMEN) ---
@app.get("/top-barangays", response_model=TopBarangaysResponse, tags=["insights"])
def get_top_barangays(top_n: int = 10):
    """
    Return top N barangays with highest crime totals.
    Example: /top-barangays?top_n=10
    """
    global top_barangays_overall

    if top_barangays_overall is None:
        raise HTTPException(status_code=500, detail="Top barangays not available (model not initialized).")

    if top_n <= 0:
        raise HTTPException(status_code=400, detail="top_n must be positive.")

    series = top_barangays_overall.head(top_n)

    data = [
        TopBarangayItem(barangay=str(idx), total=int(val))
        for idx, val in series.items()
    ]

    return TopBarangaysResponse(status="success", top_n=len(data), data=data)


# ---------- 4) POSSIBLE CRIMES PER MONTH ---------------
@app.get("/possible-crimes", response_model=PossibleCrimesResponse, tags=["insights"])
def get_possible_crimes_for_month(date: str):
    """
    Given a date, return the top 3 historical crimes for that calendar month.
    Example: /possible-crimes?date=2025-03-01
    """
    global top_crimes_by_month

    if top_crimes_by_month is None:
        raise HTTPException(status_code=500, detail="Top crimes by month not available (model not initialized).")

    # parse date
    try:
        d = pd.to_datetime(date)
    except Exception:
        raise HTTPException(status_code=400, detail="Invalid date format. Use YYYY-MM-DD.")

    m = d.month
    sub = top_crimes_by_month[top_crimes_by_month["month"] == m]

    if sub.empty:
        raise HTTPException(status_code=404, detail="No crime history for that month.")

    data = [
        PossibleCrimeItem(
            crime_type=row["crime_type"],
            total_5years=int(row["total"])
        )
        for _, row in sub.iterrows()
    ]

    return PossibleCrimesResponse(
        status="success",
        month=m,
        month_name=month_name_from_int(m),
        data=data
    )
# ---------- 5) BARANGAY COORDINATES FOR MAP -------------

@app.get("/barangays-coords", response_model=BarangayCoordsResponse, tags=["map"])
def get_barangay_coords():
    """
    Returns one coordinate (centroid) per barangay with total crimes.
    Use this for mapping barangay markers / clusters.
    """
    global barangay_coords_global

    if barangay_coords_global is None or barangay_coords_global.empty:
        raise HTTPException(status_code=500, detail="Barangay coordinates not available (model not initialized).")

    data = [
        BarangayCoordItem(
            barangay=str(row["barangay"]),
            lat=float(row["lat"]),
            lng=float(row["lng"]),
            total=int(row["total"])
        )
        for _, row in barangay_coords_global.iterrows()
    ]

    return BarangayCoordsResponse(
        status="success",
        data=data
    )


@app.get("/metrics", tags=["metrics"])
def get_metrics(horizon: int = 12):
    """Return holdout RMSE and MAPE using the last `horizon` months (default 12)."""
    try:
        m = compute_holdout_metrics(horizon=horizon)
        return {"status": "success", "metrics": m}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/hotspots", tags=["map"])
def get_hotspots(months: int = 12, top_n: int = 10):
    """Return top N barangays with highest crime totals in the last `months` months.
    Includes lat/lng and total counts.
    """
    if df_global is None:
        raise HTTPException(status_code=500, detail="Data not loaded (model not initialized).")

    # cutoff date
    last_date = ts.index[-1]
    cutoff = last_date - pd.DateOffset(months=months)

    recent = df_global[df_global["date"] > cutoff]
    if recent.empty:
        raise HTTPException(status_code=404, detail="No data for requested window")

    agg = (
        recent.groupby("barangay")["crime_count"]
              .sum()
              .reset_index()
              .rename(columns={"crime_count": "total"})
    )

    # join coords if available
    if barangay_coords_global is not None:
        agg = agg.merge(barangay_coords_global[["barangay", "lat", "lng"]], on="barangay", how="left")
    else:
        agg["lat"] = None
        agg["lng"] = None

    agg = agg.sort_values("total", ascending=False).head(top_n).reset_index(drop=True)

    items = []
    for _, row in agg.iterrows():
        items.append({
            "barangay": str(row["barangay"]),
            "total": int(row["total"]),
            "lat": (None if pd.isna(row.get("lat")) else float(row.get("lat"))) ,
            "lng": (None if pd.isna(row.get("lng")) else float(row.get("lng"))) ,
        })

    return {"status": "success", "window_months": months, "top_n": len(items), "data": items}


@app.get("/trends", tags=["insights"]) 
def get_trends(months: int = 36, ma_window: int = 3):
    """Return monthly totals, moving average, MoM and YoY percent change for the last `months` months."""
    if ts is None:
        raise HTTPException(status_code=500, detail="Time series not available (model not initialized).")

    df_ts = ts.reset_index().rename(columns={"date": "date", "crime_count": "total"})
    df_ts = df_ts.tail(months).copy()
    df_ts["ma"] = df_ts["crime_count"].rolling(window=ma_window, min_periods=1).mean()
    df_ts["mom_pct"] = df_ts["crime_count"].pct_change() * 100
    df_ts["yoy_pct"] = df_ts["crime_count"].pct_change(periods=12) * 100

    data = []
    for idx, row in df_ts.iterrows():
        data.append({
            "date": str(row["date"].date()),
            "total": float(row["crime_count"]),
            "ma": (None if isnan(row["ma"]) else float(row["ma"])),
            "mom_pct": (None if isnan(row["mom_pct"]) else float(row["mom_pct"])),
            "yoy_pct": (None if isnan(row["yoy_pct"]) else float(row["yoy_pct"])),
        })

    return {"status": "success", "months": len(data), "data": data}


@app.get("/possible-crimes-extended", response_model=PossibleCrimesResponse, tags=["insights"])
def get_possible_crimes_for_month_extended(date: str, top_k: int = 3):
    """Given a date, return top K historical crimes for that calendar month plus probability based on 5-year data."""
    global top_crimes_by_month

    if top_crimes_by_month is None:
        raise HTTPException(status_code=500, detail="Top crimes by month not available (model not initialized).")

    # parse date
    try:
        d = pd.to_datetime(date)
    except Exception:
        raise HTTPException(status_code=400, detail="Invalid date format. Use YYYY-MM-DD.")

    m = d.month
    sub = top_crimes_by_month[top_crimes_by_month["month"] == m]

    if sub.empty:
        raise HTTPException(status_code=404, detail="No crime history for that month.")

    # compute monthly totals for the month to get probabilities
    month_totals = sub["total"].sum()
    items = []
    for _, row in sub.head(top_k).iterrows():
        prob = (row["total"] / month_totals) if month_totals > 0 else 0.0
        items.append(PossibleCrimeItem(crime_type=row["crime_type"], total_5years=int(row["total"])))

    return PossibleCrimesResponse(status="success", month=m, month_name=month_name_from_int(m), data=items)


if __name__ == "__main__":
    # Guard server start to avoid reloader/spawn recursion on Windows.
    try:
        import uvicorn

        uvicorn.run("sarima_api.Sarimax:app", host="127.0.0.1", port=8000, reload=True)
    except Exception:
        pass
